{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copyright 2020 Vraj Shah, Arun Kumar\n",
    "#\n",
    "#Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#you may not use this file except in compliance with the License.\n",
    "#You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#Unless required by applicable law or agreed to in writing, software\n",
    "#distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#See the License for the specific language governing permissions and\n",
    "#limitations under the License.\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "import enchant\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "# np.random.seed(512)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>numeric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>context-specific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>not-generalizable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>not-generalizable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7936 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  y_act\n",
       "0               numeric\n",
       "1               numeric\n",
       "2               numeric\n",
       "3           categorical\n",
       "4               numeric\n",
       "...                 ...\n",
       "7931            numeric\n",
       "7932        categorical\n",
       "7933   context-specific\n",
       "7934  not-generalizable\n",
       "7935  not-generalizable\n",
       "\n",
       "[7936 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = pd.read_csv('../../Benchmark-Labeled-Data/data_train.csv')\n",
    "xtest = pd.read_csv('../../Benchmark-Labeled-Data/data_test.csv')\n",
    "\n",
    "\n",
    "xtrain = xtrain.sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "print(len(xtrain))\n",
    "\n",
    "y_train = xtrain.loc[:,['y_act']]\n",
    "y_test = xtest.loc[:,['y_act']]\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7936 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_act\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         0\n",
       "...     ...\n",
       "7931      0\n",
       "7932      1\n",
       "7933      8\n",
       "7934      7\n",
       "7935      7\n",
       "\n",
       "[7936 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_label = {\n",
    "    'numeric': 0,\n",
    "    'categorical': 1,\n",
    "    'datetime': 2,\n",
    "    'sentence': 3,\n",
    "    'url': 4,\n",
    "    'embedded-number': 5,\n",
    "    'list': 6,\n",
    "    'not-generalizable': 7,\n",
    "    'context-specific': 8\n",
    "}\n",
    "\n",
    "y_train['y_act'] = [dict_label[i] for i in y_train['y_act']]\n",
    "y_test['y_act'] = [dict_label[i] for i in y_test['y_act']]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessStats(data,y):\n",
    "\n",
    "    data1 = data[['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean',\n",
    "        'std_dev', 'min_val', 'max_val','has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n",
    "       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n",
    "       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n",
    "       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n",
    "       'is_list', 'is_long_sentence']]\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    data1 = data1.fillna(0)\n",
    "\n",
    "    def abs_limit(x):\n",
    "        if abs(x) > 10000:\n",
    "            return 10000*np.sign(x)\n",
    "        return x\n",
    "\n",
    "    column_names_to_normalize = ['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean',\n",
    "        'std_dev', 'min_val', 'max_val','has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n",
    "       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n",
    "       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n",
    "       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n",
    "       'is_list', 'is_long_sentence']\n",
    "    \n",
    "    for col in column_names_to_normalize:\n",
    "        data1[col] = data1[col].apply(abs_limit)\n",
    "    \n",
    "    print(column_names_to_normalize)\n",
    "    x = data1[column_names_to_normalize].values\n",
    "    x = np.nan_to_num(x)\n",
    "    x_scaled = StandardScaler().fit_transform(x)\n",
    "    df_temp = pd.DataFrame(x_scaled, columns=column_names_to_normalize, index=data1.index)\n",
    "    data1[column_names_to_normalize] = df_temp\n",
    "\n",
    "\n",
    "    y.y_act = y.y_act.astype(float)\n",
    "\n",
    "    print(f\"> Data mean: {data1.mean()}\\n\")\n",
    "    print(f\"> Data median: {data1.median()}\\n\")\n",
    "    print(f\"> Data stdev: {data1.std()}\")\n",
    "    \n",
    "    return data1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerName = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "vectorizerSample = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "\n",
    "def FeatureExtraction(data,data1,flag):\n",
    "    arr = data['Attribute_name'].values\n",
    "    arr = [str(x) for x in arr]\n",
    "    print(len(arr))\n",
    "    # data = data.fillna(0)\n",
    "    arr1 = data['sample_1'].values\n",
    "    arr1 = [str(x) for x in arr1]\n",
    "    arr2 = data['sample_2'].values\n",
    "    arr2 = [str(x) for x in arr2]  \n",
    "    \n",
    "    \n",
    "    print(len(arr1),len(arr2))\n",
    "    if flag:\n",
    "        X = vectorizerName.fit_transform(arr)\n",
    "        X1 = vectorizerSample.fit_transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)   \n",
    "        \n",
    "    else:\n",
    "        X = vectorizerName.transform(arr)\n",
    "        X1 = vectorizerSample.transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)    \n",
    "\n",
    "    attr_df = pd.DataFrame(X.toarray())\n",
    "    sample1_df = pd.DataFrame(X1.toarray())\n",
    "    sample2_df = pd.DataFrame(X2.toarray())\n",
    "    \n",
    "    print(len(data1),len(attr_df),len(sample1_df),len(sample2_df))\n",
    "    data2 = pd.concat([data1, attr_df,sample1_df,sample2_df], axis=1, sort=False)\n",
    "#     data2 = pd.concat([attr_df, sample1_df], axis=1, sort=False)\n",
    "#     data2 = pd.concat([sample1_df, sample2_df, sample3_df, sample4_df], axis=1, sort=False)\n",
    "#     print(len(data2))\n",
    "    return data2\n",
    "#     return sample1_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val', 'max_val', 'has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count', 'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total', 'mean_char_count', 'stdev_char_count', 'mean_whitespace_count', 'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count', 'is_list', 'is_long_sentence']\n",
      "> Data mean: total_vals               -3.939501e-17\n",
      "num_nans                 -3.044160e-17\n",
      "%_nans                   -5.260129e-17\n",
      "num_of_dist_val          -2.865092e-17\n",
      "%_dist_val                7.341797e-17\n",
      "mean                     -4.387172e-17\n",
      "std_dev                  -2.686023e-18\n",
      "min_val                  -4.029035e-17\n",
      "max_val                   9.848753e-18\n",
      "has_delimiters           -3.581365e-17\n",
      "has_url                   2.686023e-17\n",
      "has_email                -9.401082e-18\n",
      "has_date                  3.984268e-17\n",
      "mean_word_count           1.096793e-17\n",
      "std_dev_word_count       -7.610400e-18\n",
      "mean_stopword_total      -1.745915e-17\n",
      "stdev_stopword_total     -2.193586e-17\n",
      "mean_char_count           1.477313e-17\n",
      "stdev_char_count          1.253478e-17\n",
      "mean_whitespace_count    -2.462188e-17\n",
      "stdev_whitespace_count   -7.610400e-18\n",
      "mean_delim_count         -2.462188e-17\n",
      "stdev_delim_count        -7.610400e-18\n",
      "is_list                  -1.208711e-17\n",
      "is_long_sentence          1.074409e-17\n",
      "dtype: float64\n",
      "\n",
      "> Data median: total_vals               -0.418152\n",
      "num_nans                 -0.495165\n",
      "%_nans                   -0.524671\n",
      "num_of_dist_val          -0.404847\n",
      "%_dist_val               -0.640074\n",
      "mean                     -0.297200\n",
      "std_dev                  -0.357867\n",
      "min_val                   0.033331\n",
      "max_val                  -0.412811\n",
      "has_delimiters           -0.327798\n",
      "has_url                  -0.120724\n",
      "has_email                -0.025109\n",
      "has_date                 -0.354955\n",
      "mean_word_count          -0.071336\n",
      "std_dev_word_count       -0.054700\n",
      "mean_stopword_total      -0.043008\n",
      "stdev_stopword_total     -0.050306\n",
      "mean_char_count          -0.100190\n",
      "stdev_char_count         -0.064882\n",
      "mean_whitespace_count    -0.071336\n",
      "stdev_whitespace_count   -0.054700\n",
      "mean_delim_count         -0.071336\n",
      "stdev_delim_count        -0.054700\n",
      "is_list                  -0.273150\n",
      "is_long_sentence         -0.196142\n",
      "dtype: float64\n",
      "\n",
      "> Data stdev: total_vals                1.000063\n",
      "num_nans                  1.000063\n",
      "%_nans                    1.000063\n",
      "num_of_dist_val           1.000063\n",
      "%_dist_val                1.000063\n",
      "mean                      1.000063\n",
      "std_dev                   1.000063\n",
      "min_val                   1.000063\n",
      "max_val                   1.000063\n",
      "has_delimiters            1.000063\n",
      "has_url                   1.000063\n",
      "has_email                 1.000063\n",
      "has_date                  1.000063\n",
      "mean_word_count           1.000063\n",
      "std_dev_word_count        1.000063\n",
      "mean_stopword_total       1.000063\n",
      "stdev_stopword_total      1.000063\n",
      "mean_char_count           1.000063\n",
      "stdev_char_count          1.000063\n",
      "mean_whitespace_count     1.000063\n",
      "stdev_whitespace_count    1.000063\n",
      "mean_delim_count          1.000063\n",
      "stdev_delim_count         1.000063\n",
      "is_list                   1.000063\n",
      "is_long_sentence          1.000063\n",
      "dtype: float64\n",
      "['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val', 'max_val', 'has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count', 'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total', 'mean_char_count', 'stdev_char_count', 'mean_whitespace_count', 'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count', 'is_list', 'is_long_sentence']\n",
      "> Data mean: total_vals                5.727297e-17\n",
      "num_nans                 -2.147736e-17\n",
      "%_nans                    8.948901e-17\n",
      "num_of_dist_val           1.431824e-17\n",
      "%_dist_val               -2.863648e-17\n",
      "mean                     -5.727297e-17\n",
      "std_dev                   4.295472e-17\n",
      "min_val                   0.000000e+00\n",
      "max_val                   7.159121e-18\n",
      "has_delimiters            5.727297e-17\n",
      "has_url                   2.147736e-17\n",
      "has_email                 0.000000e+00\n",
      "has_date                 -5.727297e-17\n",
      "mean_word_count          -1.431824e-17\n",
      "std_dev_word_count        1.431824e-17\n",
      "mean_stopword_total      -2.147736e-17\n",
      "stdev_stopword_total      1.431824e-17\n",
      "mean_char_count           1.431824e-17\n",
      "stdev_char_count         -1.073868e-17\n",
      "mean_whitespace_count    -1.431824e-17\n",
      "stdev_whitespace_count    1.431824e-17\n",
      "mean_delim_count         -1.431824e-17\n",
      "stdev_delim_count         1.431824e-17\n",
      "is_list                  -2.863648e-17\n",
      "is_long_sentence          1.431824e-17\n",
      "dtype: float64\n",
      "\n",
      "> Data median: total_vals               -0.138039\n",
      "num_nans                 -0.487427\n",
      "%_nans                   -0.518688\n",
      "num_of_dist_val          -0.415981\n",
      "%_dist_val               -0.623727\n",
      "mean                     -0.285933\n",
      "std_dev                  -0.346564\n",
      "min_val                   0.059300\n",
      "max_val                  -0.405741\n",
      "has_delimiters           -0.318675\n",
      "has_url                  -0.125956\n",
      "has_email                 0.000000\n",
      "has_date                 -0.363792\n",
      "mean_word_count          -0.109839\n",
      "std_dev_word_count       -0.065591\n",
      "mean_stopword_total      -0.073964\n",
      "stdev_stopword_total     -0.061197\n",
      "mean_char_count          -0.125770\n",
      "stdev_char_count         -0.064649\n",
      "mean_whitespace_count    -0.109839\n",
      "stdev_whitespace_count   -0.065591\n",
      "mean_delim_count         -0.109839\n",
      "stdev_delim_count        -0.065591\n",
      "is_list                  -0.260343\n",
      "is_long_sentence         -0.191190\n",
      "dtype: float64\n",
      "\n",
      "> Data stdev: total_vals                1.000252\n",
      "num_nans                  1.000252\n",
      "%_nans                    1.000252\n",
      "num_of_dist_val           1.000252\n",
      "%_dist_val                1.000252\n",
      "mean                      1.000252\n",
      "std_dev                   1.000252\n",
      "min_val                   1.000252\n",
      "max_val                   1.000252\n",
      "has_delimiters            1.000252\n",
      "has_url                   1.000252\n",
      "has_email                 0.000000\n",
      "has_date                  1.000252\n",
      "mean_word_count           1.000252\n",
      "std_dev_word_count        1.000252\n",
      "mean_stopword_total       1.000252\n",
      "stdev_stopword_total      1.000252\n",
      "mean_char_count           1.000252\n",
      "stdev_char_count          1.000252\n",
      "mean_whitespace_count     1.000252\n",
      "stdev_whitespace_count    1.000252\n",
      "mean_delim_count          1.000252\n",
      "stdev_delim_count         1.000252\n",
      "is_list                   1.000252\n",
      "is_long_sentence          1.000252\n",
      "dtype: float64\n",
      "7936\n",
      "7936 7936\n",
      "7936 7936 7936 7936\n",
      "1985\n",
      "1985 1985\n",
      "1985 1985 1985 1985\n",
      "==========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 0.0001, accuracy: 0.391304347826087]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 0.001, accuracy: 0.6704473850031506]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 0.01, accuracy: 0.792690611216131]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 0.1, accuracy: 0.851291745431632]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 1, accuracy: 0.8620037807183365]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 10, accuracy: 0.8582230623818525]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 100, accuracy: 0.8500315059861374]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 1000, accuracy: 0.847511027095148]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 10000, accuracy: 0.8500315059861374]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C: 100000, accuracy: 0.851291745431632]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/adriana/Documents/ML-Data-Prep-Zoo/MLFeatureTypeInference/Source-Code/Models/Logistic_Regression.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adriana/Documents/ML-Data-Prep-Zoo/MLFeatureTypeInference/Source-Code/Models/Logistic_Regression.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m bscr_train \u001b[39m=\u001b[39m bestPerformingModel\u001b[39m.\u001b[39mscore(X_train_cur, y_train_cur)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adriana/Documents/ML-Data-Prep-Zoo/MLFeatureTypeInference/Source-Code/Models/Logistic_Regression.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m bscr \u001b[39m=\u001b[39m bestPerformingModel\u001b[39m.\u001b[39mscore(X_test_cur, y_test_cur)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/adriana/Documents/ML-Data-Prep-Zoo/MLFeatureTypeInference/Source-Code/Models/Logistic_Regression.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m bscr_hld \u001b[39m=\u001b[39m bestPerformingModel\u001b[39m.\u001b[39;49mscore(X_test, y_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adriana/Documents/ML-Data-Prep-Zoo/MLFeatureTypeInference/Source-Code/Models/Logistic_Regression.ipynb#W5sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m avgsc_train_lst\u001b[39m.\u001b[39mappend(bscr_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/adriana/Documents/ML-Data-Prep-Zoo/MLFeatureTypeInference/Source-Code/Models/Logistic_Regression.ipynb#W5sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m avgsc_lst\u001b[39m.\u001b[39mappend(bscr)\n",
      "File \u001b[0;32m~/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/base.py:668\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    644\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    664\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\u001b[39;00m\n\u001b[1;32m    665\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[0;32m--> 668\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[39mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    407\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 419\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    421\u001b[0m     indices \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/linear_model/_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    397\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    398\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 400\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    401\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[1;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39mreshape(scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mno_validation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[39m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_feature_names(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    550\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m estimator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mrequires y to be passed, but the target y is None.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/base.py:425\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    424\u001b[0m fitted_feature_names \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfeature_names_in_\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 425\u001b[0m X_feature_names \u001b[39m=\u001b[39m _get_feature_names(X)\n\u001b[1;32m    427\u001b[0m \u001b[39mif\u001b[39;00m fitted_feature_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m X_feature_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     \u001b[39m# no feature names seen in fit and in X\u001b[39;00m\n\u001b[1;32m    429\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1903\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m   1901\u001b[0m \u001b[39m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[1;32m   1902\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(types) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m types:\n\u001b[0;32m-> 1903\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   1904\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFeature names are only supported if all input features have string names, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1905\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut your input has \u001b[39m\u001b[39m{\u001b[39;00mtypes\u001b[39m}\u001b[39;00m\u001b[39m as feature name / column name types. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1906\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1907\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1908\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1909\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdata, or convert them all to a non-string data type.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1910\u001b[0m     )\n\u001b[1;32m   1912\u001b[0m \u001b[39m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(types) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m types[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mstr\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "xtrain1 = ProcessStats(xtrain,y_train)\n",
    "xtest1 = ProcessStats(xtest,y_test)\n",
    "\n",
    "\n",
    "X_train = FeatureExtraction(xtrain,xtrain1,1)\n",
    "X_test = FeatureExtraction(xtest,xtest1,0)\n",
    "\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values\n",
    "\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, random_state = 100, shuffle=True)\n",
    "avg_train_acc, avg_test_acc = 0, 0\n",
    "\n",
    "val_arr = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000]\n",
    "\n",
    "avgsc_lst, avgsc_train_lst, avgsc_hld_lst = [], [], []\n",
    "avgsc, avgsc_train, avgsc_hld = 0, 0, 0\n",
    "\n",
    "best_param_count = {'cval': {}}\n",
    "for train_index, test_index in kf.split(X_train_new):\n",
    "    X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "    y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "    X_train_train, X_val, y_train_train, y_val = train_test_split(\n",
    "        X_train_cur, y_train_cur, test_size=0.25, random_state=100)\n",
    "\n",
    "    bestPerformingModel = LogisticRegression(\n",
    "        penalty='l2', multi_class='multinomial', solver='lbfgs', C=1)\n",
    "    bestscore = 0\n",
    "    print('='*10)\n",
    "    for val in val_arr:\n",
    "        clf = LogisticRegression(\n",
    "            penalty='l2', multi_class='multinomial', solver='lbfgs', C=val)\n",
    "        clf.fit(X_train_train, y_train_train)\n",
    "        sc = clf.score(X_val, y_val)\n",
    "        print(f\"[C: {val}, accuracy: {sc}]\")\n",
    "        if bestscore < sc:\n",
    "            bestcval = val\n",
    "            bestscore = sc\n",
    "            bestPerformingModel = clf\n",
    "    \n",
    "    if str(bestcval) in best_param_count['cval']:\n",
    "        best_param_count['cval'][str(bestcval)] += 1\n",
    "    else:\n",
    "        best_param_count['cval'][str(bestcval)] = 1\n",
    "        \n",
    "    bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "    bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "    bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "\n",
    "    avgsc_train_lst.append(bscr_train)\n",
    "    avgsc_lst.append(bscr)\n",
    "    avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "    avgsc_train = avgsc_train + bscr_train\n",
    "    avgsc = avgsc + bscr\n",
    "    avgsc_hld = avgsc_hld + bscr_hld\n",
    "    print()\n",
    "    print(f\"> Best C: {bestcval}\")\n",
    "    print(f\"> Best training score: {bscr_train}\")\n",
    "    print(f\"> Best test score: {bscr}\")\n",
    "    print(f\"> Best held score: {bscr_hld}\")\n",
    "print('='*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9569943289224953, 0.9576311230114979, 0.9573161127736651, 0.9544810206331705, 0.9530634745629233]\n",
      "[0.8683879093198993, 0.8626339004410838, 0.8575929426591052, 0.8720856962822936, 0.8695652173913043]\n",
      "[0.8659949622166246, 0.8675062972292191, 0.8594458438287154, 0.853904282115869, 0.8584382871536524]\n",
      "0.9558972119807503\n",
      "0.8660531332187373\n",
      "0.8610579345088162\n",
      "0.8584382871536524\n"
     ]
    }
   ],
   "source": [
    "print(avgsc_train_lst)\n",
    "print(avgsc_lst)\n",
    "print(avgsc_hld_lst)\n",
    "\n",
    "print(avgsc_train/k)\n",
    "print(avgsc/k)\n",
    "print(avgsc_hld/k)\n",
    "\n",
    "y_pred = bestPerformingModel.predict(X_test)\n",
    "bscr_hld = bestPerformingModel.score(X_test, y_test)\n",
    "print(bscr_hld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPerformingModel.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def PrintMetrics(y_true, y_pred):\n",
    "    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
    "\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(matrix)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 score: {f1}')\n",
    "\n",
    "\n",
    "PrintMetrics(y_test, bestPerformingModel.predict(X_test.to_numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
