{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "import pickle\n",
    "import math\n",
    "import re\n",
    "import enchant\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "np.random.seed(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936\n"
     ]
    }
   ],
   "source": [
    "xtrain = pd.read_csv('../MLFeatureTypeInference/Benchmark-Labeled-Data/data_train.csv')\n",
    "xtest = pd.read_csv('../MLFeatureTypeInference/Benchmark-Labeled-Data/data_test.csv')\n",
    "\n",
    "\n",
    "xtrain = xtrain.sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "print(len(xtrain))\n",
    "\n",
    "y_train = xtrain.loc[:,['y_act']]\n",
    "y_test = xtest.loc[:,['y_act']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_act</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7931</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7932</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7933</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7934</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7935</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7936 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      y_act\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         1\n",
       "4         0\n",
       "...     ...\n",
       "7931      0\n",
       "7932      1\n",
       "7933      8\n",
       "7934      7\n",
       "7935      7\n",
       "\n",
       "[7936 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_label = {\n",
    "    'numeric': 0,\n",
    "    'categorical': 1,\n",
    "    'datetime': 2,\n",
    "    'sentence': 3,\n",
    "    'url': 4,\n",
    "    'embedded-number': 5,\n",
    "    'list': 6,\n",
    "    'not-generalizable': 7,\n",
    "    'context-specific': 8\n",
    "}\n",
    "\n",
    "y_train['y_act'] = [dict_label[i] for i in y_train['y_act']]\n",
    "y_test['y_act'] = [dict_label[i] for i in y_test['y_act']]\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useStats = 1\n",
    "useAttributeName = 1\n",
    "useSample1 = 0\n",
    "useSample2 = 0\n",
    "## Using descriptive stats and attribute name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ProcessStats(data,y):\n",
    "\n",
    "    data1 = data[['total_vals', 'num_nans', '%_nans', 'num_of_dist_val', '%_dist_val', 'mean', 'std_dev', 'min_val', 'max_val','has_delimiters', 'has_url', 'has_email', 'has_date', 'mean_word_count',\n",
    "       'std_dev_word_count', 'mean_stopword_total', 'stdev_stopword_total',\n",
    "       'mean_char_count', 'stdev_char_count', 'mean_whitespace_count',\n",
    "       'stdev_whitespace_count', 'mean_delim_count', 'stdev_delim_count',\n",
    "       'is_list', 'is_long_sentence']]\n",
    "    data1 = data1.reset_index(drop=True)\n",
    "    data1 = data1.fillna(0)\n",
    "\n",
    "    y.y_act = y.y_act.astype(float)\n",
    "    \n",
    "    return data1\n",
    "\n",
    "\n",
    "vectorizerName = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "vectorizerSample = CountVectorizer(ngram_range=(2, 2), analyzer='char')\n",
    "\n",
    "def FeatureExtraction(data,data1,flag):\n",
    "\n",
    "    arr = data['Attribute_name'].values\n",
    "    arr = [str(x) for x in arr]\n",
    "    \n",
    "    arr1 = data['sample_1'].values\n",
    "    arr1 = [str(x) for x in arr1]\n",
    "    arr2 = data['sample_2'].values\n",
    "    arr2 = [str(x) for x in arr2]\n",
    "    arr3 = data['sample_3'].values\n",
    "    arr3 = [str(x) for x in arr3]    \n",
    "    print(len(arr1),len(arr2))\n",
    "    if flag:\n",
    "        X = vectorizerName.fit_transform(arr)\n",
    "        X1 = vectorizerSample.fit_transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)   \n",
    "        \n",
    "    else:\n",
    "        X = vectorizerName.transform(arr)\n",
    "        X1 = vectorizerSample.transform(arr1)\n",
    "        X2 = vectorizerSample.transform(arr2)        \n",
    "        \n",
    "#     print(f\"> Length of vectorized feature_names: {len(vectorizer.get_feature_names())}\")\n",
    "\n",
    "    attr_df = pd.DataFrame(X.toarray())\n",
    "    sample1_df = pd.DataFrame(X1.toarray())\n",
    "    sample2_df = pd.DataFrame(X2.toarray())\n",
    "    print(len(data1),len(attr_df),len(sample1_df),len(sample2_df))\n",
    "\n",
    "    if useSample1: data2 = sample1_df\n",
    "    if useSample2: data2 = sample2_df    \n",
    "    \n",
    "    data2 = pd.concat([data1, attr_df], axis=1, sort=False)\n",
    "    print(len(data2))\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7936 7936\n",
      "7936 7936 7936 7936\n",
      "7936\n",
      "1985 1985\n",
      "1985 1985 1985 1985\n",
      "1985\n",
      "==========\n",
      "[max_depth: 5, accuracy: 0.7939508506616257]\n",
      "[max_depth: 10, accuracy: 0.8872085696282294]\n",
      "[max_depth: 25, accuracy: 0.8979206049149339]\n",
      "[max_depth: 50, accuracy: 0.8979206049149339]\n",
      "[max_depth: 100, accuracy: 0.8979206049149339]\n",
      "[max_depth: 250, accuracy: 0.8979206049149339]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:227: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "[max_depth: 5, accuracy: 0.7991183879093199]\n",
      "[max_depth: 10, accuracy: 0.8904282115869018]\n",
      "[max_depth: 25, accuracy: 0.9030226700251889]\n",
      "[max_depth: 50, accuracy: 0.9030226700251889]\n",
      "[max_depth: 100, accuracy: 0.9030226700251889]\n",
      "[max_depth: 250, accuracy: 0.9030226700251889]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:227: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "[max_depth: 5, accuracy: 0.7959697732997482]\n",
      "[max_depth: 10, accuracy: 0.8759445843828715]\n",
      "[max_depth: 25, accuracy: 0.8872795969773299]\n",
      "[max_depth: 50, accuracy: 0.8872795969773299]\n",
      "[max_depth: 100, accuracy: 0.8872795969773299]\n",
      "[max_depth: 250, accuracy: 0.8872795969773299]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:227: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "[max_depth: 5, accuracy: 0.801007556675063]\n",
      "[max_depth: 10, accuracy: 0.878463476070529]\n",
      "[max_depth: 25, accuracy: 0.889168765743073]\n",
      "[max_depth: 50, accuracy: 0.889168765743073]\n",
      "[max_depth: 100, accuracy: 0.889168765743073]\n",
      "[max_depth: 250, accuracy: 0.889168765743073]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:227: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "[max_depth: 5, accuracy: 0.77455919395466]\n",
      "[max_depth: 10, accuracy: 0.8841309823677582]\n",
      "[max_depth: 25, accuracy: 0.8835012594458438]\n",
      "[max_depth: 50, accuracy: 0.8835012594458438]\n",
      "[max_depth: 100, accuracy: 0.8835012594458438]\n",
      "[max_depth: 250, accuracy: 0.8835012594458438]\n",
      "==========\n",
      "[0.9743226212980466, 0.974956686092298, 0.9713340683572216, 0.9718065837139707, 0.9310127579146322]\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.8931989924433249, 0.8987405541561713, 0.8942065491183879, 0.8806045340050378, 0.8831234256926952]\n",
      "0.9646865434752337\n",
      "0.0\n",
      "0.8899748110831235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adriana/Documents/ML-Data-Prep-Zoo/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:227: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831234256926952\n"
     ]
    }
   ],
   "source": [
    "xtrain1 = ProcessStats(xtrain,y_train)\n",
    "xtest1 = ProcessStats(xtest,y_test)\n",
    "\n",
    "\n",
    "X_train = FeatureExtraction(xtrain,xtrain1,1)\n",
    "X_test = FeatureExtraction(xtest,xtest1,0)\n",
    "\n",
    "\n",
    "X_train_new = X_train.reset_index(drop=True)\n",
    "y_train_new = y_train.reset_index(drop=True)\n",
    "X_train_new = X_train_new.values\n",
    "y_train_new = y_train_new.values\n",
    "\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k,random_state = 100, shuffle=True)\n",
    "avg_train_acc,avg_test_acc = 0,0\n",
    "\n",
    "max_depth_grid = [5,10,25,50,100,250]\n",
    "# criterion_grid = ['gini', 'entropy', 'log_loss']\n",
    "criterion_grid = ['log_loss']\n",
    "\n",
    "# n_estimators_grid = [25,50,75,100]\n",
    "# max_depth_grid = [50,100]\n",
    "\n",
    "avgsc_lst,avgsc_train_lst,avgsc_hld_lst = [],[],[]\n",
    "avgsc,avgsc_train,avgsc_hld = 0,0,0\n",
    "\n",
    "i=0\n",
    "for train_index, test_index in kf.split(X_train_new):\n",
    "#     if i==1: break\n",
    "    i=i+1\n",
    "    X_train_cur, X_test_cur = X_train_new[train_index], X_train_new[test_index]\n",
    "    y_train_cur, y_test_cur = y_train_new[train_index], y_train_new[test_index]\n",
    "    y_test_cur = [str(val) for val in y_test_cur]\n",
    "    X_train_train, X_val,y_train_train,y_val = train_test_split(X_train_cur,y_train_cur, test_size=0.25,random_state=100)\n",
    "\n",
    "    bestPerformingModel = DecisionTreeClassifier(criterion='gini',max_depth=5,random_state=100)\n",
    "    bestscore = 0\n",
    "    print('='*10)\n",
    "    for md in max_depth_grid:\n",
    "        for cr in criterion_grid:\n",
    "            clf = DecisionTreeClassifier(max_depth=md, criterion=cr, random_state=100)\n",
    "            clf.fit(X_train_train, y_train_train.ravel())\n",
    "            sc = clf.score(X_val, y_val)\n",
    "            print(f\"[max_depth: {md}, accuracy: {sc}]\")\n",
    "            if bestscore < sc:\n",
    "                bestmd = md\n",
    "                bestcr = cr\n",
    "                bestscore = sc\n",
    "                bestPerformingModel = clf\n",
    "\n",
    "    bscr_train = bestPerformingModel.score(X_train_cur, y_train_cur)\n",
    "    bscr = bestPerformingModel.score(X_test_cur, y_test_cur)\n",
    "    bscr_hld = bestPerformingModel.score(X_test.to_numpy(), y_test)\n",
    "\n",
    "    avgsc_train_lst.append(bscr_train)\n",
    "    avgsc_lst.append(bscr)\n",
    "    avgsc_hld_lst.append(bscr_hld)\n",
    "\n",
    "    avgsc_train = avgsc_train + bscr_train    \n",
    "    avgsc = avgsc + bscr\n",
    "    avgsc_hld = avgsc_hld + bscr_hld\n",
    "\n",
    "    # print()\n",
    "    # print(f\"> Best n_estimator: {bestne} || Best max_depth: {bestmd}\")\n",
    "    # print(f\"> Best training score: {bscr_train}\")\n",
    "    # print(f\"> Best test score: {bscr}\")\n",
    "    # print(f\"> Best held score: {bscr_hld}\")\n",
    "print('='*10)\n",
    "\n",
    "print(avgsc_train_lst)\n",
    "print(avgsc_lst)\n",
    "print(avgsc_hld_lst)\n",
    "\n",
    "print(avgsc_train/k)\n",
    "print(avgsc/k)\n",
    "print(avgsc_hld/k)\n",
    "\n",
    "y_pred = bestPerformingModel.predict(X_test.to_numpy())\n",
    "bscr_hld = bestPerformingModel.score(X_test.to_numpy(), y_test)\n",
    "print(bscr_hld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8831234256926952\n",
      "10\n",
      "log_loss\n",
      "0.8841309823677582\n"
     ]
    }
   ],
   "source": [
    "print(bestPerformingModel.score(X_test.to_numpy(), y_test))\n",
    "\n",
    "print(bestmd)\n",
    "print(bestcr)\n",
    "print(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8831234256926952\n",
      "[[668  19   0   0   0   0   0   3  17]\n",
      " [ 29 409   0   1   1   2   2   6   7]\n",
      " [  2   0 138   0   0   0   0   0   1]\n",
      " [  0   6   0  71   0   0   6   6   3]\n",
      " [  0   2   0   1  28   0   1   0   0]\n",
      " [  1   3   1   0   0  89   2   0   3]\n",
      " [  0   4   0   3   0   2  46   1   1]\n",
      " [  8   4   0   1   0   0   0 197   5]\n",
      " [ 47  21   1   5   0   0   1   3 107]]\n",
      "Precision: [0.88476821 0.87393162 0.98571429 0.86585366 0.96551724 0.95698925\n",
      " 0.79310345 0.91203704 0.74305556]\n",
      "Recall: [0.94483734 0.89496718 0.9787234  0.77173913 0.875      0.8989899\n",
      " 0.80701754 0.91627907 0.57837838]\n",
      "F1 score: [0.91381669 0.88432432 0.98220641 0.81609195 0.91803279 0.92708333\n",
      " 0.8        0.91415313 0.65045593]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def PrintMetrics(y_true, y_pred):\n",
    "    print(f'Accuracy: {accuracy_score(y_true, y_pred)}')\n",
    "\n",
    "    matrix = confusion_matrix(y_true, y_pred)\n",
    "    print(matrix)\n",
    "\n",
    "    precision = precision_score(y_true, y_pred, average=None)\n",
    "    recall = recall_score(y_true, y_pred, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, average=None)\n",
    "\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1 score: {f1}')\n",
    "\n",
    "\n",
    "PrintMetrics(y_test, bestPerformingModel.predict(X_test.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini\n",
    "\n",
    "Accuracy: 0.8926952141057934\n",
    "[[669  13   0   0   0   0   0   5  20]\n",
    " [ 16 418   0   5   1   1   0   2  14]\n",
    " [  0   0 138   0   0   0   0   1   2]\n",
    " [  0   2   0  81   1   0   2   3   3]\n",
    " [  0   0   0   0  31   0   1   0   0]\n",
    " [  1   5   2   0   0  87   1   0   3]\n",
    " [  0   1   1   3   0   1  44   0   7]\n",
    " [  6  12   4   1   0   0   0 188   4]\n",
    " [ 41  21   1   4   0   0   0   2 116]]\n",
    "Precision: [0.91268759 0.88559322 0.94520548 0.86170213 0.93939394 0.97752809\n",
    " 0.91666667 0.93532338 0.68639053]\n",
    "Recall: [0.94625177 0.91466083 0.9787234  0.88043478 0.96875    0.87878788\n",
    " 0.77192982 0.8744186  0.62702703]\n",
    "F1 score: [0.92916667 0.89989236 0.96167247 0.87096774 0.95384615 0.92553191\n",
    " 0.83809524 0.90384615 0.65536723]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy\n",
    "\n",
    "Accuracy: 0.8831234256926952\n",
    "[[668  19   0   0   0   0   0   3  17]\n",
    " [ 29 409   0   1   1   2   2   6   7]\n",
    " [  2   0 138   0   0   0   0   0   1]\n",
    " [  0   6   0  71   0   0   6   6   3]\n",
    " [  0   2   0   1  28   0   1   0   0]\n",
    " [  1   3   1   0   0  89   2   0   3]\n",
    " [  0   4   0   3   0   2  46   1   1]\n",
    " [  8   4   0   1   0   0   0 197   5]\n",
    " [ 47  21   1   5   0   0   1   3 107]]\n",
    "Precision: [0.88476821 0.87393162 0.98571429 0.86585366 0.96551724 0.95698925\n",
    " 0.79310345 0.91203704 0.74305556]\n",
    "Recall: [0.94483734 0.89496718 0.9787234  0.77173913 0.875      0.8989899\n",
    " 0.80701754 0.91627907 0.57837838]\n",
    "F1 score: [0.91381669 0.88432432 0.98220641 0.81609195 0.91803279 0.92708333\n",
    " 0.8        0.91415313 0.65045593]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
